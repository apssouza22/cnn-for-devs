{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_olmp4cIedJi"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apssouza22/cnn-for-devs/blob/master/g-image-similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZyY8beAwWo"
      },
      "source": [
        "Image search - Find similar images\n",
        "======\n",
        "\n",
        "In this session we will learn how to build a image search engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "QeU9mB0_AwWs"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9mhRUHRAwWt"
      },
      "source": [
        "Parameter Settings\n",
        "-------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flbWQTlZAwWu"
      },
      "source": [
        "MNIST Data Loading\n",
        "-------------------\n",
        "\n",
        "MNIST images show digits from 0-9 in 28x28 grayscale images. We normalize and center them around 0, which gives a slight performance boost during training.\n",
        "We create both a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6uK2neSDAwWv"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "full_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
        "full_dataloader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "qDRI4FededJp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TuvFZ3TkedJq"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        c = capacity\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=c, kernel_size=4, stride=2, padding=1) # out: c x 14 x 14\n",
        "        self.conv2 = nn.Conv2d(in_channels=c, out_channels=c*2, kernel_size=4, stride=2, padding=1) # out: c x 7 x 7\n",
        "        self.fc = nn.Linear(in_features=conv_dim, out_features=latent_dims)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1) # flatten batch of multi-channel feature maps to a batch of feature vectors\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        c = capacity\n",
        "        self.fc = nn.Linear(in_features=latent_dims, out_features=c*2*7*7)\n",
        "        self.conv2 = nn.ConvTranspose2d(in_channels=c*2, out_channels=c, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv1 = nn.ConvTranspose2d(in_channels=c, out_channels=1, kernel_size=4, stride=2, padding=1)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.size(0), capacity*2, 7, 7) # unflatten batch of feature vectors to a batch of multi-channel feature maps\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.tanh(self.conv1(x)) # last layer before output is tanh, since the images are normalized and 0-centered\n",
        "        return x\n",
        "    \n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        x_recon = self.decoder(latent)\n",
        "        return x_recon\n",
        "    \n",
        "autoencoder = Autoencoder()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "autoencoder = autoencoder.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "F-6mqVszAwWu"
      },
      "outputs": [],
      "source": [
        "latent_dims = 10\n",
        "batch_size = 128\n",
        "capacity = 64\n",
        "conv_dim = capacity * 2 * 7 * 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKqkmN51AwWz"
      },
      "source": [
        "Load Pre-Trained Autoencoder\n",
        "-----------------------------\n",
        "\n",
        "In this lesson we will leverage from the Autoencoder model we created in the previous lesson. Please run the notebook and upload the wheights generated in assets folder. <a href=\"https://colab.research.google.com/github/apssouza22/cnn-for-devs/blob/master/f-image-interpolation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-zHUB8hAwW0",
        "outputId": "788303b8-48b8-4913-bd79-703e9e2e42ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "autoencoder.decoder.load_state_dict(torch.load('./assets/decoder.pth'))\n",
        "autoencoder.encoder.load_state_dict(torch.load('./assets/encoder.pth'))\n",
        "\n",
        "# this is how the autoencoder parameters can be saved:\n",
        "# torch.save(autoencoder.state_dict(), './assets/my_autoencoder.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzgXndbGAwW0"
      },
      "source": [
        "Evaluate on the Test Set\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fwptU4XAwW0",
        "outputId": "14777168-16c5-42b7-eafd-a9efb72c2330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average reconstruction error: 0.048161\n"
          ]
        }
      ],
      "source": [
        "# set to evaluation mode\n",
        "autoencoder.eval()\n",
        "\n",
        "test_loss_avg, num_batches = 0, 0\n",
        "for image_batch, _ in test_dataloader:\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        image_batch = image_batch.to(device)\n",
        "\n",
        "        # autoencoder reconstruction\n",
        "        image_batch_recon = autoencoder(image_batch)\n",
        "\n",
        "        # reconstruction error\n",
        "        loss = F.mse_loss(image_batch_recon, image_batch)\n",
        "\n",
        "        test_loss_avg += loss.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "test_loss_avg /= num_batches\n",
        "print('average reconstruction error: %f' % (test_loss_avg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGOZhBrEAwW1"
      },
      "source": [
        "Create embedding from the latent space\n",
        "--------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SGs6dUcFs4cB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def create_embedding(encoder, full_loader, embedding_dim, device):\n",
        "    \"\"\"\n",
        "    Creates embedding using encoder from dataloader.\n",
        "    encoder: A convolutional Encoder. E.g. torch_model ConvEncoder\n",
        "    full_loader: PyTorch dataloader, containing (images, images) over entire dataset.\n",
        "    embedding_dim: Tuple (c, h, w) Dimension of embedding = output of encoder dimesntions.\n",
        "    device: \"cuda\" or \"cpu\"\n",
        "    Returns: Embedding of size (num_images_in_loader + 1, c, h, w)\n",
        "    \"\"\"\n",
        "    # Set encoder to eval mode.\n",
        "    encoder.eval()\n",
        "    # Just a place holder for our 0th image embedding.\n",
        "    \n",
        "    # embedding = torch.randn(embedding_dim)\n",
        "    embedding = None\n",
        "    labels = []\n",
        "    # print(embedding.shape)\n",
        "    # Again we do not compute loss here so. No gradients.\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (train_img, target_img) in enumerate(full_loader):\n",
        "            for _,val in enumerate(target_img):\n",
        "              labels.append(val.item())\n",
        "              \n",
        "            train_img = train_img.to(device)\n",
        "            # Get encoder outputs and move outputs to cpu\n",
        "            enc_output = encoder(train_img).cpu()\n",
        "            if  embedding is not None:\n",
        "              # embedding = torch.cat((embedding, enc_output), 0)\n",
        "              embedding = np.row_stack((embedding, enc_output))\n",
        "            else:\n",
        "              embedding = enc_output\n",
        "\n",
        "    return  {\"labels\": labels, \"features\": embedding}\n",
        "\n",
        "EMBEDDING_SHAPE = (conv_dim, latent_dims)\n",
        "index = create_embedding(autoencoder.encoder, full_dataloader, EMBEDDING_SHAPE, device)\n",
        "# np.save(\"data_embedding.npy\", index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dAAG9L6jC8t9"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# compute and return the euclidean distance between two vectors\n",
        "def euclidean(a, b):\n",
        "\treturn np.linalg.norm(a - b)\n",
        "\n",
        "def perform_search(queryFeatures, index, maxResults=64):\n",
        "\tresults = []\n",
        "\n",
        "\t# loop over our index\n",
        "\tfor i in range(0, len(index[\"features\"])):\n",
        "\t\t# compute the euclidean distance between our query features and the features for the current image in our index, then\n",
        "\t\t# update our results list with a 2-tuple consisting of the computed distance and the index of the image\n",
        "\t\tdistance = euclidean(queryFeatures, index[\"features\"][i])\n",
        "\t\tresults.append((distance, i))\n",
        "\n",
        "\t# sort the results and grab the top ones\n",
        "\tresults = sorted(results)[:maxResults]\n",
        "\n",
        "\t# return the list of results\n",
        "\treturn results\n",
        "\n",
        "def compute_similar_images(img1, num_images, embedding, device):\n",
        "    with torch.no_grad():\n",
        "      img1 = img1.to(device)\n",
        "      image_embedding = autoencoder.encoder(img1).cpu().detach().numpy()\n",
        "    indices_list = perform_search(image_embedding, index, maxResults=num_images)\n",
        "\n",
        "    return indices_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Wgg-LOtFw7WO"
      },
      "outputs": [],
      "source": [
        "# sort part of test set by digit\n",
        "digits = [[] for _ in range(10)]\n",
        "for img_batch, label_batch in test_dataloader:\n",
        "    for i in range(img_batch.size(0)):\n",
        "        digits[label_batch[i]].append(img_batch[i:i+1])\n",
        "\n",
        "    if sum(len(d) for d in digits) >= 1000:\n",
        "        break;\n",
        "        \n",
        "def to_img(x):\n",
        "    x = 0.5 * (x + 1)\n",
        "    x = x.clamp(0, 1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Searching for images with number 7"
      ],
      "metadata": {
        "id": "DrLx4oIhgSBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "fZxiJG71w2W2",
        "outputId": "16c8f3e2-c479-4d13-80a4-42215c4338a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,7,7,7,7,7,7,7,7,7,\n",
            "[(7.009884e-07, 69935), (0.69210887, 54219), (0.88183856, 69864), (0.928874, 19780), (1.0040549, 16247), (1.0450412, 63040), (1.0536106, 40117), (1.068364, 50380), (1.0873239, 52405), (1.0875529, 25581)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "img = digits[7][0]\n",
        "indices_list = compute_similar_images(img, 10, index[\"features\"], device)\n",
        "\n",
        "labels =\"\"\n",
        "for i,val in enumerate(indices_list):\n",
        "  labels += str(index[\"labels\"][val[1]]) + \",\"\n",
        "\n",
        "print(labels)\n",
        "print(indices_list)\n",
        "\n",
        "fig, axs = plt.subplots(2,5, figsize=(15, 6))\n",
        "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "for i,val in enumerate(indices_list):\n",
        "  img, lbl = full_dataloader.dataset[val[1]]\n",
        "  inter_image = to_img(img)\n",
        "  image = inter_image.numpy()\n",
        "  axs[i].imshow(img.squeeze(), cmap='gray')\n",
        "\n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2_YH-SmrgENg"
      },
      "execution_count": 28,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}