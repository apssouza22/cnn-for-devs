{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_olmp4cIedJi"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apssouza22/cnn-for-devs/blob/master/g-image-similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZyY8beAwWo"
      },
      "source": [
        "Image search - Finding similar images\n",
        "======\n",
        "\n",
        "In this session we will learn how to build a image search engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QeU9mB0_AwWs"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9mhRUHRAwWt"
      },
      "source": [
        "Parameter Settings\n",
        "-------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "num_epochs = 30\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "use_gpu = True\n",
        "img_size = 64\n",
        "conv_dim = 64 * 2 * 7 * 7"
      ],
      "metadata": {
        "id": "E3nFY3rX53Yo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flbWQTlZAwWu"
      },
      "source": [
        "MNIST Data Loading\n",
        "-------------------\n",
        "\n",
        "MNIST images show digits from 0-9 in 28x28 grayscale images. We normalize and center them around 0, which gives a slight performance boost during training.\n",
        "We create both a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6uK2neSDAwWv"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "full_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
        "full_dataloader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qDRI4FededJp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TuvFZ3TkedJq",
        "outputId": "7464f498-26e2-4add-a2cd-7084c7c0d083",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 396171\n"
          ]
        }
      ],
      "source": [
        "# Model responsible for generating our Latent space.\n",
        "#Latent space, Typically it is a 100-dimensional hypersphere with each variable drawn from a Gaussian distribution with a mean of zero and a standard deviation of one\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=img_size, kernel_size=4, stride=2, padding=1) # out: c x 14 x 14\n",
        "        self.conv2 = nn.Conv2d(in_channels=img_size, out_channels=img_size*2, kernel_size=4, stride=2, padding=1) # out: c x 7 x 7\n",
        "        self.fc = nn.Linear(in_features=img_size * 2 * 7 * 7, out_features=num_classes)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1) # flatten batch of multi-channel feature maps to a batch of feature vectors\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Model responsible for reconstruct the image form our Latent space.\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.fc = nn.Linear(in_features=num_classes, out_features=img_size*2*7*7)\n",
        "        self.conv2 = nn.ConvTranspose2d(in_channels=img_size * 2, out_channels=img_size, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv1 = nn.ConvTranspose2d(in_channels=img_size, out_channels=1, kernel_size=4, stride=2, padding=1)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.size(0), img_size * 2, 7, 7) # unflatten batch of feature vectors to a batch of multi-channel feature maps\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = torch.tanh(self.conv1(x)) # last layer before output is tanh, since the images are normalized and 0-centered\n",
        "        return x\n",
        "    \n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Encoder()\n",
        "        self.decoder = Decoder()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        x_recon = self.decoder(latent)\n",
        "        return x_recon\n",
        "    \n",
        "autoencoder = Autoencoder()\n",
        "\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "autoencoder = autoencoder.to(device)\n",
        "\n",
        "#The modelâ€™s parameters that need to be trained.\n",
        "num_params = sum(p.numel() for p in autoencoder.parameters() if p.requires_grad)\n",
        "print('Number of parameters: %d' % num_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F-6mqVszAwWu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKqkmN51AwWz"
      },
      "source": [
        "Load Pre-Trained Autoencoder\n",
        "-----------------------------\n",
        "\n",
        "In this lesson we will leverage from the Autoencoder model we created in the previous lesson. Please run the notebook and upload the wheights generated in assets folder. <a href=\"https://colab.research.google.com/github/apssouza22/cnn-for-devs/blob/master/f-image-interpolation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-zHUB8hAwW0",
        "outputId": "36a3d00b-98ad-455b-83c7-8a7c496547e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "autoencoder.decoder.load_state_dict(torch.load('./assets/decoder.pth'))\n",
        "autoencoder.encoder.load_state_dict(torch.load('./assets/encoder.pth'))\n",
        "\n",
        "# this is how the autoencoder parameters can be saved:\n",
        "# torch.save(autoencoder.state_dict(), './assets/my_autoencoder.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzgXndbGAwW0"
      },
      "source": [
        "Evaluate on the Test Set\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fwptU4XAwW0",
        "outputId": "92b94145-3329-4f89-a793-c8eee57ac5f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average reconstruction error: 0.048187\n"
          ]
        }
      ],
      "source": [
        "# set to evaluation mode\n",
        "autoencoder.eval()\n",
        "\n",
        "test_loss_avg, num_batches = 0, 0\n",
        "for image_batch, _ in test_dataloader:\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        image_batch = image_batch.to(device)\n",
        "\n",
        "        # autoencoder reconstruction\n",
        "        image_batch_recon = autoencoder(image_batch)\n",
        "\n",
        "        # reconstruction error\n",
        "        loss = F.mse_loss(image_batch_recon, image_batch)\n",
        "\n",
        "        test_loss_avg += loss.item()\n",
        "        num_batches += 1\n",
        "    \n",
        "test_loss_avg /= num_batches\n",
        "print('average reconstruction error: %f' % (test_loss_avg))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGOZhBrEAwW1"
      },
      "source": [
        "Create embedding from the latent space\n",
        "--------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SGs6dUcFs4cB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def create_embedding(encoder, full_loader, embedding_dim, device):\n",
        "    \"\"\"\n",
        "    Creates embedding using encoder from dataloader.\n",
        "    encoder: A convolutional Encoder. E.g. torch_model ConvEncoder\n",
        "    full_loader: PyTorch dataloader, containing (images, images) over entire dataset.\n",
        "    embedding_dim: Tuple (c, h, w) Dimension of embedding = output of encoder dimesntions.\n",
        "    device: \"cuda\" or \"cpu\"\n",
        "    Returns: Embedding of size (num_images_in_loader + 1, c, h, w)\n",
        "    \"\"\"\n",
        "    # Set encoder to eval mode.\n",
        "    encoder.eval()\n",
        "    # Just a place holder for our 0th image embedding.\n",
        "    \n",
        "    # embedding = torch.randn(embedding_dim)\n",
        "    embedding = None\n",
        "    labels = []\n",
        "    # print(embedding.shape)\n",
        "    # Again we do not compute loss here so. No gradients.\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (train_img, target_img) in enumerate(full_loader):\n",
        "            for _,val in enumerate(target_img):\n",
        "              labels.append(val.item())\n",
        "              \n",
        "            train_img = train_img.to(device)\n",
        "            # Get encoder outputs and move outputs to cpu\n",
        "            enc_output = encoder(train_img).cpu()\n",
        "            if  embedding is not None:\n",
        "              # embedding = torch.cat((embedding, enc_output), 0)\n",
        "              embedding = np.row_stack((embedding, enc_output))\n",
        "            else:\n",
        "              embedding = enc_output\n",
        "\n",
        "    return  {\"labels\": labels, \"features\": embedding}\n",
        "\n",
        "EMBEDDING_SHAPE = (conv_dim, num_classes)\n",
        "index = create_embedding(autoencoder.encoder, full_dataloader, EMBEDDING_SHAPE, device)\n",
        "# np.save(\"data_embedding.npy\", index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search images based on the embedding\n",
        "\n",
        "Let's calculate the distance of two image latent space using euclidean algorithm "
      ],
      "metadata": {
        "id": "0xTmL5z465YC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dAAG9L6jC8t9"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "# compute and return the euclidean distance between two vectors\n",
        "def euclidean(a, b):\n",
        "\treturn np.linalg.norm(a - b)\n",
        "\n",
        "def perform_search(queryFeatures, index, maxResults=64):\n",
        "\tresults = []\n",
        "\n",
        "\t# loop over our index\n",
        "\tfor i in range(0, len(index[\"features\"])):\n",
        "\t\t# compute the euclidean distance between our query features and the features for the current image in our index, then\n",
        "\t\t# update our results list with a 2-tuple consisting of the computed distance and the index of the image\n",
        "\t\tdistance = euclidean(queryFeatures, index[\"features\"][i])\n",
        "\t\tresults.append((distance, i))\n",
        "\n",
        "\t# sort the results and grab the top ones\n",
        "\tresults = sorted(results)[:maxResults]\n",
        "\n",
        "\t# return the list of results\n",
        "\treturn results\n",
        "\n",
        "def get_similar_images(img1, num_images, embedding, device):\n",
        "    with torch.no_grad():\n",
        "      img1 = img1.to(device)\n",
        "      image_embedding = autoencoder.encoder(img1).cpu().detach().numpy()\n",
        "    indices_list = perform_search(image_embedding, index, maxResults=num_images)\n",
        "\n",
        "    return indices_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Wgg-LOtFw7WO"
      },
      "outputs": [],
      "source": [
        "# Grouping digits in a map\n",
        "digits = [[] for _ in range(10)]\n",
        "for img_batch, label_batch in test_dataloader:\n",
        "    for i in range(img_batch.size(0)):\n",
        "        digits[label_batch[i]].append(img_batch[i:i+1])\n",
        "\n",
        "    if sum(len(d) for d in digits) >= 1000:\n",
        "        break;\n",
        "        \n",
        "def to_img(x):\n",
        "    x = 0.5 * (x + 1)\n",
        "    x = x.clamp(0, 1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Searching for images with number 7"
      ],
      "metadata": {
        "id": "DrLx4oIhgSBw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZxiJG71w2W2",
        "outputId": "90312cbb-87b5-49d7-aaf2-36183318a69c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,7,7,7,7,7,7,7,7,7,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(6.165552e-07, 66316),\n",
              " (0.87777346, 4298),\n",
              " (1.0640293, 60941),\n",
              " (1.0887965, 30307),\n",
              " (1.1517854, 19668),\n",
              " (1.156041, 26063),\n",
              " (1.1594676, 34353),\n",
              " (1.2225678, 48861),\n",
              " (1.2349106, 64459),\n",
              " (1.2357744, 29423)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "img = digits[7][0]\n",
        "indices_list = get_similar_images(img, 10, index[\"features\"], device)\n",
        "\n",
        "labels =\"\"\n",
        "for i,val in enumerate(indices_list):\n",
        "  labels += str(index[\"labels\"][val[1]]) + \",\"\n",
        "\n",
        "print(labels)\n",
        "indices_list\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2,5, figsize=(15, 6))\n",
        "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
        "axs = axs.ravel()\n",
        "\n",
        "for i,val in enumerate(indices_list):\n",
        "  img, lbl = full_dataloader.dataset[val[1]]\n",
        "  inter_image = to_img(img)\n",
        "  image = inter_image.numpy()\n",
        "  axs[i].imshow(img.squeeze(), cmap='gray')\n",
        "\n",
        "plt.show() "
      ],
      "metadata": {
        "id": "jwQgAlEJ7_4Y",
        "outputId": "8a361566-f8cd-438d-cb49-b11790754bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2_YH-SmrgENg"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "autoencoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}