{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/apssouza22/cnn-for-devs/blob/master/g-image-similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oZyY8beAwWo"
   },
   "source": [
    "Image search - Find similar images\n",
    "======\n",
    "\n",
    "In this session we will learn how to build a image search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QeU9mB0_AwWs"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9mhRUHRAwWt"
   },
   "source": [
    "Parameter Settings\n",
    "-------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "F-6mqVszAwWu"
   },
   "outputs": [],
   "source": [
    "latent_dims = 10\n",
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "capacity = 64\n",
    "learning_rate = 1e-3\n",
    "use_gpu = True\n",
    "conv_dim = capacity * 2 * 7 * 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flbWQTlZAwWu"
   },
   "source": [
    "MNIST Data Loading\n",
    "-------------------\n",
    "\n",
    "MNIST images show digits from 0-9 in 28x28 grayscale images. We normalize and center them around 0, which gives a slight performance boost during training.\n",
    "We create both a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6uK2neSDAwWv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5afd37c6b684d22b5624d9d786575a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbf8942da8844bfb0301495632c75a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "485ab44df6e04490a2e63b354d881b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e30a2d2e1b55434a9a43beff07c22f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root='./data/MNIST', download=True, train=True, transform=img_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = MNIST(root='./data/MNIST', download=True, train=False, transform=img_transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "full_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
    "full_dataloader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=c, kernel_size=4, stride=2, padding=1) # out: c x 14 x 14\n",
    "        self.conv2 = nn.Conv2d(in_channels=c, out_channels=c*2, kernel_size=4, stride=2, padding=1) # out: c x 7 x 7\n",
    "        self.fc = nn.Linear(in_features=conv_dim, out_features=latent_dims)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1) # flatten batch of multi-channel feature maps to a batch of feature vectors\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        c = capacity\n",
    "        self.fc = nn.Linear(in_features=latent_dims, out_features=c*2*7*7)\n",
    "        self.conv2 = nn.ConvTranspose2d(in_channels=c*2, out_channels=c, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv1 = nn.ConvTranspose2d(in_channels=c, out_channels=1, kernel_size=4, stride=2, padding=1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), capacity*2, 7, 7) # unflatten batch of feature vectors to a batch of multi-channel feature maps\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = torch.tanh(self.conv1(x)) # last layer before output is tanh, since the images are normalized and 0-centered\n",
    "        return x\n",
    "    \n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        x_recon = self.decoder(latent)\n",
    "        return x_recon\n",
    "    \n",
    "autoencoder = Autoencoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKqkmN51AwWz"
   },
   "source": [
    "Load Pre-Trained Autoencoder\n",
    "-----------------------------\n",
    "\n",
    "In this lesson we will leverage from the Autoencoder model we created in the previous lesson. Please run the notebook and upload the wheights generated in assets folder. <a href=\"https://colab.research.google.com/github/apssouza22/cnn-for-devs/blob/master/f-image-interpolation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-zHUB8hAwW0",
    "outputId": "90d57af6-995c-456b-a36c-5adf570f84c0"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f5eab98ec97a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./assets/decoder.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./assets/encoder.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# this is how the autoencoder parameters can be saved:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# torch.save(autoencoder.state_dict(), './assets/my_autoencoder.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    590\u001b[0m                                   \" silence this warning)\", UserWarning)\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    845\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(obj, size, key, location)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0msize_long\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<Q\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    139\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "autoencoder.decoder.load_state_dict(torch.load('./assets/decoder.pth'))\n",
    "autoencoder.encoder.load_state_dict(torch.load('./assets/encoder.pth'))\n",
    "\n",
    "# this is how the autoencoder parameters can be saved:\n",
    "# torch.save(autoencoder.state_dict(), './assets/my_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzgXndbGAwW0"
   },
   "source": [
    "Evaluate on the Test Set\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fwptU4XAwW0",
    "outputId": "c9162097-a023-452f-dac1-4de222eef12b"
   },
   "outputs": [],
   "source": [
    "# set to evaluation mode\n",
    "autoencoder.eval()\n",
    "\n",
    "test_loss_avg, num_batches = 0, 0\n",
    "for image_batch, _ in test_dataloader:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        image_batch = image_batch.to(device)\n",
    "\n",
    "        # autoencoder reconstruction\n",
    "        image_batch_recon = autoencoder(image_batch)\n",
    "\n",
    "        # reconstruction error\n",
    "        loss = F.mse_loss(image_batch_recon, image_batch)\n",
    "\n",
    "        test_loss_avg += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "test_loss_avg /= num_batches\n",
    "print('average reconstruction error: %f' % (test_loss_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGOZhBrEAwW1"
   },
   "source": [
    "Visualize Reconstructions\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGs6dUcFs4cB",
    "outputId": "4ba0e7c8-e89b-4ddf-b7da-2a69ac313834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating tensor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_embedding(encoder, full_loader, embedding_dim, device):\n",
    "    \"\"\"\n",
    "    Creates embedding using encoder from dataloader.\n",
    "    encoder: A convolutional Encoder. E.g. torch_model ConvEncoder\n",
    "    full_loader: PyTorch dataloader, containing (images, images) over entire dataset.\n",
    "    embedding_dim: Tuple (c, h, w) Dimension of embedding = output of encoder dimesntions.\n",
    "    device: \"cuda\" or \"cpu\"\n",
    "    Returns: Embedding of size (num_images_in_loader + 1, c, h, w)\n",
    "    \"\"\"\n",
    "    # Set encoder to eval mode.\n",
    "    encoder.eval()\n",
    "    # Just a place holder for our 0th image embedding.\n",
    "    \n",
    "    # embedding = torch.randn(embedding_dim)\n",
    "    embedding = None\n",
    "    labels = []\n",
    "    # print(embedding.shape)\n",
    "    # Again we do not compute loss here so. No gradients.\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (train_img, target_img) in enumerate(full_loader):\n",
    "            for _,val in enumerate(target_img):\n",
    "              labels.append(val.item())\n",
    "              \n",
    "            train_img = train_img.to(device)\n",
    "            # Get encoder outputs and move outputs to cpu\n",
    "            enc_output = encoder(train_img).cpu()\n",
    "            if  embedding is not None:\n",
    "              # embedding = torch.cat((embedding, enc_output), 0)\n",
    "              embedding = np.row_stack((embedding, enc_output))\n",
    "              \n",
    "            else:\n",
    "              print(\"creating tensor\")\n",
    "              embedding = enc_output\n",
    "\n",
    "    return  {\"labels\": labels, \"features\": embedding}\n",
    "\n",
    "EMBEDDING_SHAPE = (conv_dim, latent_dims)\n",
    "index = create_embedding(autoencoder.encoder, full_dataloader, EMBEDDING_SHAPE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "dAAG9L6jC8t9"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# compute and return the euclidean distance between two vectors\n",
    "def euclidean(a, b):\n",
    "\treturn np.linalg.norm(a - b)\n",
    "\n",
    "def perform_search(queryFeatures, index, maxResults=64):\n",
    "\tresults = []\n",
    "\n",
    "\t# loop over our index\n",
    "\tfor i in range(0, len(index[\"features\"])):\n",
    "\t\t# compute the euclidean distance between our query features and the features for the current image in our index, then\n",
    "\t\t# update our results list with a 2-tuple consisting of the computed distance and the index of the image\n",
    "\t\tdistance = euclidean(queryFeatures, index[\"features\"][i])\n",
    "\t\tresults.append((distance, i))\n",
    "\n",
    "\t# sort the results and grab the top ones\n",
    "\tresults = sorted(results)[:maxResults]\n",
    "\n",
    "\t# return the list of results\n",
    "\treturn results\n",
    "\n",
    "def compute_similar_images(img1, num_images, embedding, device):\n",
    "    with torch.no_grad():\n",
    "      img1 = img1.to(device)\n",
    "      image_embedding = autoencoder.encoder(img1).cpu().detach().numpy()\n",
    "    indices_list = perform_search(image_embedding, index, maxResults=num_images)\n",
    "\n",
    "    return indices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkkJcCGfv2yV",
    "outputId": "a5f7a991-6f39-4150-d11d-aa5bf5047cbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([76272, 10])\n"
     ]
    }
   ],
   "source": [
    "# print(embedding.shape)\n",
    "# np.save(\"data_embedding.npy\", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bq43J-zXwzwl"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Wgg-LOtFw7WO"
   },
   "outputs": [],
   "source": [
    "# sort part of test set by digit\n",
    "digits = [[] for _ in range(10)]\n",
    "for img_batch, label_batch in test_dataloader:\n",
    "    for i in range(img_batch.size(0)):\n",
    "        digits[label_batch[i]].append(img_batch[i:i+1])\n",
    "\n",
    "    if sum(len(d) for d in digits) >= 1000:\n",
    "        break;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "fZxiJG71w2W2",
    "outputId": "f445619b-4725-46ae-9ada-f262a239b956"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,7,7,7,7,7,7,7,7,7,\n",
      "[(6.021733e-07, 67978), (1.5984244, 28201), (1.907501, 13091), (1.9263319, 65297), (1.9482344, 6115), (1.950679, 36796), (2.1586654, 17163), (2.1928153, 60676), (2.2439678, 20619), (2.245177, 14391)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = digits[7][0]\n",
    "indices_list = compute_similar_images(img, 10, index[\"features\"], device)\n",
    "\n",
    "labels =\"\"\n",
    "for i,val in enumerate(indices_list):\n",
    "  labels += str(index[\"labels\"][val[1]]) + \",\"\n",
    "\n",
    "print(labels)\n",
    "print(indices_list)\n",
    "\n",
    "fig, axs = plt.subplots(2,5, figsize=(15, 6))\n",
    "fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "for i,val in enumerate(indices_list):\n",
    "  img, lbl = full_dataloader.dataset[val[1]]\n",
    "  inter_image = to_img(img)\n",
    "  image = inter_image.numpy()\n",
    "  axs[i].imshow(img.squeeze(), cmap='gray')\n",
    "\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
